import os
from io import BytesIO

# LangChain Components
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_openai import OpenAIEmbeddings # Used for embeddings

# --- CONFIGURATION (Replace with your actual values) ---
# It's better to use environment variables, but for simplicity here we use placeholders
# This replicates the setup from your 'app.py' image
API_KEY = "sk-6V7eTYULKN..." # REPLACE WITH YOUR ACTUAL KEY
BASE_URL = "https://genailab.tcs.in/..." # REPLACE WITH YOUR ACTUAL BASE URL
MODEL_NAME = "azure_ai/genailab-maas-gpt-4o"
# --------------------------------------------------------

# The embeddings model often needs a separate API key or configuration.
# If your TCS base_url and API_KEY also handle embeddings, use that.
# For standard setup, we'll assume a standard OpenAI-compatible setup.
# You might need to adjust this depending on how your specific environment handles embeddings.
embeddings_model = OpenAIEmbeddings(
    api_key=API_KEY,
    base_url=BASE_URL # Use the same base URL if it hosts the embedding model
)

def process_documents(uploaded_files):
    """
    Loads, splits documents, and creates a Chroma vector store.
    """
    documents = []
    for uploaded_file in uploaded_files:
        # Save the uploaded file content to a temporary BytesIO stream
        bytes_data = uploaded_file.getvalue()
        file_like_object = BytesIO(bytes_data)

        if uploaded_file.name.endswith(".pdf"):
            # PyPDFLoader needs a file path, so we'll save it temporarily
            with open(f"/tmp/{uploaded_file.name}", "wb") as f:
                f.write(bytes_data)
            loader = PyPDFLoader(f"/tmp/{uploaded_file.name}")
        elif uploaded_file.name.endswith(".txt"):
            # TextLoader can load from the in-memory stream by decoding
            content = file_like_object.read().decode("utf-8")
            loader = TextLoader(file_like_object.name, encoding='utf-8')
            # The TextLoader needs a file path to initialize, but we can override content
            # A simpler approach for Streamlit is often to just read the text:
            from langchain.schema import Document
            doc = Document(page_content=content, metadata={"source": uploaded_file.name})
            documents.append(doc)
            continue
        else:
            continue

        try:
            documents.extend(loader.load())
        except Exception as e:
            print(f"Error loading {uploaded_file.name}: {e}")

    if not documents:
        return None

    # Split documents
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    splits = text_splitter.split_documents(documents)

    # Create and return the vector store
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings_model
    )
    return vectorstore

def generate_summary(vectorstore):
    """
    Sets up the RAG chain and generates a structured summary.
    """
    llm = ChatOpenAI(
        api_key=API_KEY,
        base_url=BASE_URL,
        model=MODEL_NAME,
        temperature=0.1 # Low temperature for factual extraction, as desired
    )

    # System instruction prompt for structured output
    template = """
    You are an expert Legal Document Analyst. Your task is to extract and summarize critical information from the provided legal contract document.
    Based ONLY on the context given, generate a STRUCTURED summary in a text format that is easy to read.

    Mandatory Output Structure:
    ---
    ### üìù Contract Summary

    **1. Title of Contract:** [Extracted Title]

    **2. Problem/Purpose Statement:** [Extracted Problem or Purpose of the contract]

    **3. Key Clauses and Terms:**
    - Clause 1: [Brief summary of key clause 1]
    - Clause 2: [Brief summary of key clause 2]
    - ... (list at least 3 critical clauses)

    **4. Obligations and Responsibilities:**
    - Party A Obligation: [Description of a major obligation for Party A]
    - Party B Obligation: [Description of a major obligation for Party B]
    - ...

    **5. Critical Dates and Deadlines:**
    - Effective Date: [Date, if found]
    - Termination Date: [Date, if found]
    - Delivery/Payment Deadline: [Date and description, if found]
    ---

    Do not include any pre-amble or post-amble text. Only output the structured summary starting with '### üìù Contract Summary'.
    """

    # Create the RetrievalQA chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", # 'stuff' is often simplest for full document summary/extraction
        retriever=vectorstore.as_retriever(),
        return_source_documents=False, # We only want the summary
        chain_type_kwargs={"prompt": template}
    )

    # The actual query is just a trigger to execute the prompt
    # Since the template contains the main instruction, the query can be simple.
    result = qa_chain.invoke({"query": "Generate the structured legal document summary based on the instruction template."})

    return result['result']
